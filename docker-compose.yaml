version: "2.2"

services:
  #################################################################################################
  # SPARK CLUSTER -- 1 MASTER + 1 WORKER
  #################################################################################################
  # spark-master:
  #   build:
  #     dockerfile: Dockerfile-Spark
  #   container_name: spark-master
  #   hostname: spark-master
  #   ports:
  #     - "8080:8080"
  #     - "7077:7077"
  #   environment:
  #     - SPARK_MODE=master
  #   command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master -h spark-master
  #   mem_limit: 512m
  #   volumes:
  #     - ./src:/opt/spark/work-dir/src
  #   networks:
  #     - lambda-network

  # spark-worker:
  #   build:
  #     dockerfile: Dockerfile-Spark
  #   container_name: spark-worker
  #   hostname: spark-worker
  #   command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark-master:7077
  #     - SPARK_WORKER_MEMORY=1g
  #     - SPARK_WORKER_CORES=2
  #   depends_on:
  #     - spark-master
  #   mem_limit: 1g
  #   ports:
  #     - "8081:8081"
  #   volumes:
  #     - ./src:/opt/spark/work-dir/src
  #   networks:
  #     - lambda-network

  spark1:
    build:
      dockerfile: Dockerfile-Spark
    container_name: spark1
    hostname: spark1
    ports:
      - "8080:8080"
      - "7077:7077"
      - "8081:8081" 
    environment:
      - SPARK_WORKER_MEMORY=1g
      - SPARK_WORKER_CORES=1
    command: ["/bin/bash", "-c", "/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master -h spark1 & /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark1:7077"]
    mem_limit: 1.5g
    volumes:
      - ./src:/opt/spark/work-dir/src
    networks:
      - lambda-network

  spark2:
    build:
      dockerfile: Dockerfile-Spark
    container_name: spark2
    hostname: spark2
    ports:
      - "9080:8080" # Spark Master Web UI (khác cổng host)
      - "9077:7077" # Spark Master (khác cổng host)
      - "9081:8081" # Spark Worker Web UI (khác cổng host) 
      - "9888:8888"
    environment:
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_CORES=2
    command: ["/bin/bash", "-c", "/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master -h spark2 & /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark2:7077"]
    mem_limit: 3g
    volumes:
      - ./src:/opt/spark/work-dir/src
    networks:
      - lambda-network

  #################################################################################################
  # KAFKA
  #################################################################################################
  broker:
    build:
      dockerfile: Dockerfile-Kafka
    container_name: broker
    hostname: broker
    mem_limit: 512m
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@broker:29093'
      KAFKA_LISTENERS: 'PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      # Replace CLUSTER_ID with a unique base64 UUID using "bin/kafka-storage.sh random-uuid"
      # See https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-storage-sh
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
    volumes:
      - ./src:/home/appuser/src
    networks:
      - lambda-network

  #################################################################################################
  # CASSANDRA (tối ưu cho dev nhỏ)
  #################################################################################################
  cassandra1:
    image: cassandra:4.1.4
    container_name: cassandra1
    hostname: cassandra1
    networks:
      - lambda-network
    ports:
      - "9042:9042"
    environment: &environment
      CASSANDRA_SEEDS: "cassandra1"
      CASSANDRA_CLUSTER_NAME: MyTestCluster
      CASSANDRA_NUM_TOKENS: 16
      CASSANDRA_USER: root
      CASSANDRA_PASSWORD: password
    mem_limit: 1.5g
    volumes:
      - ./cassandra-env.sh:/etc/cassandra/cassandra-env.sh

  #################################################################################################
  # HADOOP (pseudo-distributed)
  #################################################################################################

  hadoop:
    build:
      dockerfile: Dockerfile-Hadoop
    container_name: hadoop
    hostname: hadoop
    command: ["/bin/bash", "/start-all.sh"]
    # restart: always
    ports:
      - "9870:9870"   # HDFS NameNode WebUI
      - "8088:8088"   # YARN ResourceManager WebUI
    env_file:
      - ./config
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
      JAVA_HOME: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.412.b08-1.el7_9.x86_64/jre
    volumes:
      - ./src:/opt/hadoop/src
      - ./start-all.sh:/start-all.sh
    networks:
      - lambda-network
    mem_limit: 1g

  datanode:
    build:
      dockerfile: Dockerfile-Hadoop
    environment:
      JAVA_HOME: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.412.b08-1.el7_9.x86_64/jre
    command: ["/bin/bash", "hdfs", "datanode"]    
    depends_on:
      - hadoop
    env_file:
      - ./config
    networks:
      - lambda-network
    mem_limit: 1024m

  #################################################################################################
  # GRAFANA
  #################################################################################################
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    networks:
      - lambda-network

#################################################################################################
# NETWORK
#################################################################################################
networks:
  lambda-network:
    driver: bridge
